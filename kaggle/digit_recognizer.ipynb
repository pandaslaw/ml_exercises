{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import exp, array, random, dot\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image. Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset: (42000, 785)\n",
      "Size of test dataset: (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../data/digit-recognizer/train.csv')\n",
    "test = pd.read_csv('../data/digit-recognizer/test.csv')\n",
    "print(f\"Size of train dataset: {train.shape}\")\n",
    "print(f\"Size of test dataset: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(np.array(train.iloc[0, 1:]).reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.array(train.iloc[1, 1:]).reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "Data preprocessing would include:\n",
    "* Standardization (numeric values are rescaled in order to have mean=0 and standard deviation=1)\n",
    "* Split the dataset on train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_y(y):\n",
    "    y_vect = np.zeros((len(y), 10))\n",
    "    y_vect[list(range(len(y))), y] = 1\n",
    "    return y_vect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:, 1:]/255.0\n",
    "y = vectorize_y(train.iloc[:, 0])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=5)\n",
    "\n",
    "# or use a subset for quick run\n",
    "# train_size = 500\n",
    "# test_size = int(train_size*0.2)\n",
    "# X_train = X_train.iloc[:train_size]\n",
    "# y_train = y_train[:train_size]\n",
    "# X_test = X_test.iloc[:test_size]\n",
    "# y_test = y_test[:test_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE LEARNING ALGORITHM\n",
    "1. Initialize weights and biases randomly\n",
    "2. Iterate over the data<br>\n",
    "    i. Compute the output of neural network using sigmoid function<br>\n",
    "    ii. Compute the loss using the square error loss function<br>\n",
    "    iii. W(new) = W(old) — α ∆W<br>\n",
    "    iv. B(new) = B(old) — α ∆B<br>\n",
    "3. Repeat in order to get minimal error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitRecognitionNN():\n",
    "    def __init__(self, structure, epochs=3, learninig_rate=0.01, mini_batch_size=10):\n",
    "        self.structure = structure\n",
    "        self.epochs = epochs\n",
    "        self.learninig_rate = learninig_rate\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        self.cost = []\n",
    "        self.params = self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        params = {}\n",
    "        for i in range(1, len(self.structure)):\n",
    "            params[f'W{i}'] = np.random.randn(self.structure[i], self.structure[i-1]) * np.sqrt(1./self.structure[i])\n",
    "            params[f'b{i}'] = np.zeros(self.structure[i])\n",
    "            print(f\"Initialized {i} layer: weights {params[f'W{i}'].shape}, biases {params[f'b{i}'].shape}\")\n",
    "        return params\n",
    "\n",
    "    def sigmoid(self, x, derivative=False):\n",
    "        if derivative:\n",
    "            return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "    def forward_pass(self, x_train):\n",
    "        self.params['A0'] = x_train\n",
    "        for i in range(1, len(self.structure)):\n",
    "            self.params[f'Z{i}'] = np.dot(self.params[f'W{i}'], self.params[f'A{i-1}'])\n",
    "            self.params[f'Z{i}'] += self.params[f'b{i}']\n",
    "            self.params[f'A{i}'] = self.sigmoid(self.params[f'Z{i}'])\n",
    "        return self.params[f'A{len(self.structure)-1}']\n",
    "\n",
    "    def backward_pass(self, x_train, y_train):\n",
    "        gradients = {}\n",
    "        last_gradient_index = len(self.structure)-1\n",
    "        cost_derivative =  self.params[f'A{last_gradient_index}'] - y_train\n",
    "        delta = cost_derivative * self.sigmoid(self.params[f'Z{last_gradient_index}'], derivative=True)\n",
    "        gradients[f'W{last_gradient_index}'] = np.dot(delta, self.params[f'A{last_gradient_index}'].transpose())\n",
    "        gradients[f'b{last_gradient_index}'] = delta\n",
    "        for i in range(len(self.structure)-2, 0, -1):\n",
    "            delta = np.dot(self.params[f'W{i+1}'].T, delta) * self.sigmoid(self.params[f'Z{i}'], derivative=True)\n",
    "            gradients[f'W{i}'] = np.dot(delta, self.params[f'A{i}'].T)\n",
    "            gradients[f'b{i}'] = delta\n",
    "        return gradients\n",
    "\n",
    "    def compute_accuracy(self, X, Y):\n",
    "        predictions = []\n",
    "        for x, y in zip(X, Y):\n",
    "            output = self.forward_pass(x)\n",
    "            pred = np.argmax(output)\n",
    "            predictions.append(pred == np.argmax(y))\n",
    "        return np.mean(predictions)\n",
    "\n",
    "    def update_mini_batch(self, mini_batch_x, mini_batch_y):\n",
    "        nabla_b = [np.zeros(self.params[f'b{i}'].shape) for i in range(1, len(self.structure))]\n",
    "        nabla_w = [np.zeros(self.params[f'W{i}'].shape) for i in range(1, len(self.structure))]\n",
    "        for x, y in zip(mini_batch_x, mini_batch_y):\n",
    "            self.forward_pass(x)\n",
    "            gradients = self.backward_pass(x, y)\n",
    "            for i in range(1, len(self.structure)):\n",
    "                nabla_b[i-1] += gradients[f'b{i}']\n",
    "                nabla_w[i-1] += gradients[f'W{i}']\n",
    "        for i in range(1, len(self.structure)):\n",
    "            self.params[f'W{i}'] -= (self.learninig_rate/len(mini_batch_x))*nabla_w[i-1]\n",
    "            self.params[f'b{i}'] -= (self.learninig_rate/len(mini_batch_y))*nabla_b[i-1]\n",
    "\n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        \"\"\"Train the neural network using mini-batch stochastic gradient descent\"\"\"\n",
    "        n = len(x_train)\n",
    "        start_time = time.time()\n",
    "        for j in range(self.epochs):\n",
    "            shuffle_index = np.random.permutation(n)\n",
    "            training_data_x = x_train.values[shuffle_index]\n",
    "            training_data_y = y_train[shuffle_index]\n",
    "            mini_batches_y = [training_data_y[k:k+self.mini_batch_size]\n",
    "                            for k in range(0, n, self.mini_batch_size)]\n",
    "            mini_batches_x = [training_data_x[k:k+self.mini_batch_size]\n",
    "                            for k in range(0, n, self.mini_batch_size)]\n",
    "            for mini_batch_x, mini_batch_y in zip(mini_batches_x, mini_batches_y):\n",
    "                self.update_mini_batch(mini_batch_x, mini_batch_y)\n",
    "            train_accuracy = self.compute_accuracy(x_train.values, y_train)\n",
    "            test_accuracy = self.compute_accuracy(x_val.values, y_val)\n",
    "            print(\"Epoch {}. Time spent: {:.2f}. Accuracy on train set: {:.2f}%. Accuracy on test set: {:.2f}%.\".format(\n",
    "                j+1, time.time() - start_time, train_accuracy*100, test_accuracy*100))\n",
    "        print(\"Finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized 1 layer: weights (128, 784), biases (128,)\n",
      "Initialized 2 layer: weights (64, 128), biases (64,)\n",
      "Initialized 3 layer: weights (10, 64), biases (10,)\n",
      "Epoch 1. Time spent: 40.46. Accuracy on train set: 11.02%. Accuracy on test set: 11.29%.\n",
      "Epoch 2. Time spent: 84.78. Accuracy on train set: 11.09%. Accuracy on test set: 11.40%.\n",
      "Epoch 3. Time spent: 132.33. Accuracy on train set: 11.12%. Accuracy on test set: 11.43%.\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "nn_structure = [784, 128, 64, 10] # [784, 350, 10]\n",
    "drnn = DigitRecognitionNN(nn_structure, epochs=3, learninig_rate=0.01, mini_batch_size=16)\n",
    "drnn.train(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      1\n",
       "1        2      1\n",
       "2        3      1\n",
       "3        4      1\n",
       "4        5      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = []\n",
    "test_normalized = test.values/255.0\n",
    "for x in test_normalized:\n",
    "    output = drnn.forward_pass(x)\n",
    "    prediction.append(np.argmax(output))\n",
    "submission = pd.DataFrame({\n",
    "    \"ImageId\": list(range(1, test.shape[0]+1)),\n",
    "    \"Label\": prediction\n",
    "})\n",
    "submission.to_csv(\"../data/digit-recognizer/digit-recognizer-submission.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

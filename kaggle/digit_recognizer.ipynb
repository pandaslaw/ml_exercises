{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling # https://github.com/pandas-profiling/pandas-profiling\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import qgrid\n",
    "from numpy import exp, array, random, dot\n",
    "import numpy.random as r\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, norm\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error, accuracy_score\n",
    "import time\n",
    "\n",
    "np.random.seed(1)\n",
    "sns.set_style(\"dark\")\n",
    "# plt.rcParams['figure.figsize'] = 12, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image. Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset: (42000, 785)\n",
      "Size of test dataset: (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../data/digit-recognizer/train.csv')\n",
    "test = pd.read_csv('../data/digit-recognizer/test.csv')\n",
    "print(f\"Size of train dataset: {train.shape}\")\n",
    "print(f\"Size of test dataset: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(np.array(train.iloc[0, 1:]).reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.array(train.iloc[1, 1:]).reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "Data preprocessing would include:\n",
    "* Standardization (numeric values are rescaled in order to have mean=0 and standard deviation=1)\n",
    "* Split the dataset on train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_y(y):\n",
    "    y_vect = np.zeros((len(y), 10))\n",
    "    y_vect[list(range(len(y))), y] = 1\n",
    "    return y_vect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:, 1:]/255\n",
    "y = train.iloc[:, 0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "y_v_train = vectorize_y(y_train)\n",
    "# y_v_test = vectorize_y(y_test)\n",
    "\n",
    "# or use a subset for quick run\n",
    "train_size = 100\n",
    "test_size = int(train_size*0.2)\n",
    "X_train = X_train.iloc[:train_size, :]\n",
    "y_v_train = y_v_train[:train_size, :]\n",
    "X_test = X_test.iloc[:test_size, :]\n",
    "y_test = y_test[:test_size]\n",
    "\n",
    "# X_train = X_train.head()\n",
    "# y_v_train = y_v_train[:5, :]\n",
    "# X_test = X_train.head()\n",
    "# y_v_test = y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE LEARNING ALGORITHM\n",
    "1. Initialize weights and biases randomly\n",
    "2. Iterate over the data<br>\n",
    "    i. Compute the output of neural network using sigmoid function<br>\n",
    "    ii. Compute the loss using the square error loss function<br>\n",
    "    iii. W(new) = W(old) — α ∆W<br>\n",
    "    iv. B(new) = B(old) — α ∆B<br>\n",
    "3. Repeat in order to get minimal error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitRecognitionNN():\n",
    "    def __init__(self, structure, epochs=3, learninig_rate=0.01):\n",
    "        self.structure = structure\n",
    "        self.epochs = epochs\n",
    "        self.learninig_rate = learninig_rate\n",
    "        self.params = self.initialize()\n",
    "        \n",
    "    def initialize(self):\n",
    "        params = {}\n",
    "        for i in range(1, len(self.structure)):\n",
    "            params[f'W{i}'] = np.random.randn(self.structure[i], self.structure[i-1]) * np.sqrt(1./self.structure[i])\n",
    "#             params[f'b{i}'] = np.random.randn(self.structure[i]) * np.sqrt(1./self.structure[i]) # r.random_sample((self.structure[i-1], 1)) \n",
    "#             print(\"Initialized {} layer: weights {}, biases {}\".format(i, params[f'W{i}'].shape, params[f'b{i}'].shape)) \n",
    "        return params\n",
    "    \n",
    "    def sigmoid(self, x, derivative=False):\n",
    "        if derivative:\n",
    "            return x * (1 - x)\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "    def forward_pass(self, x_train):\n",
    "        self.params['A0'] = x_train\n",
    "        for i in range(1, len(self.structure)):\n",
    "            self.params[f'Z{i}'] = np.dot(self.params[f'W{i}'], self.params[f'A{i-1}'])\n",
    "#             self.params[f'Z{i}'] += self.params[f'b{i}']\n",
    "            self.params[f'A{i}'] = self.sigmoid(self.params[f'Z{i}'])\n",
    "        return self.params[f'A{len(self.structure)-1}']\n",
    "    \n",
    "    def backward_pass(self, y_train, output):\n",
    "        gradients = {}\n",
    "        error = y_train - output\n",
    "        last_gradient_index = len(self.structure)-1\n",
    "        gradients[f'W{last_gradient_index}'] = np.dot(error, self.params[f'A{last_gradient_index}'])\n",
    "#         gradients[f'b{last_gradient_index}'] = np.sum(error)#, axis=1, keepdims=True)\n",
    "        for i in range(len(self.structure)-2, 0, -1):\n",
    "            a = np.dot(error, self.params[f'W{i+1}']).T\n",
    "            error = np.multiply(a, self.sigmoid(self.params[f'Z{i}'], derivative=True))\n",
    "            gradients[f'W{i}'] = np.dot(error, self.params[f'A{i}'].T)\n",
    "#             gradients[f'b{i}'] = np.sum(error)#, axis=1, keepdims=True)\n",
    "        return gradients\n",
    "    \n",
    "    def update_weights(self, gradients):\n",
    "        for key, value in self.params.items():\n",
    "            if 'W' in key or 'b' in key:\n",
    "                self.params[key] -= self.learninig_rate * gradients[key]\n",
    "                \n",
    "    def compute_accuracy(self, X, Y):\n",
    "        predictions = []\n",
    "        for x, y in zip(X, Y):\n",
    "            output = self.forward_pass(x)\n",
    "            pred = np.argmax(output)\n",
    "            predictions.append(pred == y)\n",
    "        summed = sum(predictions) / 100.0\n",
    "        return np.average(summed)\n",
    "\n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        start_time = time.time()\n",
    "        print(f'Starting to train neural networks with {self.epochs} epochs.')\n",
    "        for epoch in range(self.epochs):\n",
    "            print(f'Iteration {epoch} of {self.epochs}.')\n",
    "            for x, y in zip(x_train.values, y_train):\n",
    "                #feed forward\n",
    "                output = self.forward_pass(x)\n",
    "                # backpropagation\n",
    "                gradients = self.backward_pass(y, output)\n",
    "                # update weights and biases\n",
    "                self.update_weights(gradients)\n",
    "            train_accuracy = self.compute_accuracy(x_train.values, np.argmax(y_train, axis=1))\n",
    "            test_accuracy = self.compute_accuracy(x_val.values, y_val)\n",
    "            print('Epoch: {0}, Time Spent: {1:.2f}s'.format(epoch+1, time.time() - start_time))\n",
    "            print(f\"\\tAccuracy on train set: {train_accuracy}.\\n\\tAccuracy on test set: {test_accuracy}.\")\n",
    "        print(\"Finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train neural networks with 3 epochs.\n",
      "Iteration 0 of 3.\n",
      "output [8.96517286e-01 1.18772993e-03 9.76434270e-01 1.85716347e-01\n",
      " 2.93808932e-04 1.56224855e-02 6.87392608e-02 7.45438496e-02\n",
      " 3.07133620e-01 7.71390208e-01]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.4903713035863695\n",
      "output [0.63792657 0.45431887 0.7367222  0.56883327 0.38625219 0.4964565\n",
      " 0.48665565 0.60100092 0.63710507 0.76941258]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.9024477985092436\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000004508\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.0000000099456168\n",
      "output [0.50000002 0.50000001 0.50000002 0.50000001 0.50000001 0.50000001\n",
      " 0.50000001 0.50000001 0.50000002 0.50000002]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000001205977105\n",
      "output [0.50013879 0.50009739 0.50017628 0.50012131 0.5000818  0.50010602\n",
      " 0.50009712 0.50012805 0.50011925 0.50016127]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.001130059595096\n",
      "output [0.50000001 0.50000001 0.50000001 0.50000001 0.50000001 0.50000001\n",
      " 0.50000001 0.50000001 0.50000001 0.50000001]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000001089048394\n",
      "output [0.50000005 0.50000004 0.50000006 0.50000005 0.50000004 0.50000005\n",
      " 0.50000004 0.50000005 0.50000005 0.50000005]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000004383819023\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.00000000424647\n",
      "output [0.50000008 0.50000007 0.50000009 0.50000007 0.50000006 0.50000007\n",
      " 0.50000008 0.50000007 0.50000008 0.50000008]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000682744438\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.00000000258344\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0000000000010507\n",
      "output [0.50001971 0.50001691 0.50002122 0.50001829 0.50001584 0.50001733\n",
      " 0.50001687 0.5000177  0.50001815 0.50001956]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0001603543031385\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000014876247\n",
      "output [0.50000001 0.50000001 0.50000001 0.50000001 0.50000001 0.50000001\n",
      " 0.50000001 0.50000001 0.50000001 0.50000001]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0000001152142945\n",
      "output [0.50003422 0.50003002 0.50003564 0.50003286 0.50002971 0.50003082\n",
      " 0.50003159 0.50003261 0.500033   0.50003407]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.000291955360378\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0000000000045732\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.00000000027971\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.0000000144004826\n",
      "output [0.50000002 0.50000002 0.50000002 0.50000002 0.50000002 0.50000002\n",
      " 0.50000002 0.50000002 0.50000002 0.50000002]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0000001632547035\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000000435\n",
      "output [0.50005724 0.50005162 0.50005955 0.5000555  0.50005133 0.50005479\n",
      " 0.5000548  0.50005604 0.50005669 0.50005861]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000504869788899\n",
      "output [0.50011173 0.50009934 0.50011128 0.50010662 0.50009777 0.50010164\n",
      " 0.50010551 0.50010506 0.50010817 0.50010737]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000955263075216\n",
      "output [0.50000312 0.50000283 0.50000319 0.50000298 0.50000277 0.50000296\n",
      " 0.50000289 0.50000294 0.50000299 0.5000032 ]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.000026943656051\n",
      "output [0.50000023 0.50000021 0.50000024 0.50000022 0.5000002  0.50000022\n",
      " 0.50000022 0.50000022 0.50000023 0.50000023]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000001994170315\n",
      "output [0.50003772 0.50003433 0.50003853 0.50003668 0.50003424 0.50003455\n",
      " 0.50003449 0.50003586 0.50003588 0.50003717]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.00032512694714\n",
      "output [0.51382802 0.51289346 0.51440788 0.51342085 0.51256117 0.51311135\n",
      " 0.51305478 0.51338763 0.51347555 0.51397321]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.1230217690454465\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000000018\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000002565654\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.000000001129087\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.000000000000374\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000008606\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.000000000057522\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000000000359\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.50019482 0.50018532 0.50019861 0.50019019 0.50018269 0.50018823\n",
      " 0.50018839 0.50019031 0.50019054 0.50019591]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.001720053563231\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.50000001 0.50000001 0.50000001 0.50000001 0.50000001 0.50000001\n",
      " 0.50000001 0.50000001 0.50000001 0.50000001]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000572266456\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.000000008280156\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000005215544\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000220165854\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.0000000001095035\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000000000027\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.50138305 0.50132259 0.50140366 0.50136078 0.50130839 0.50133596\n",
      " 0.5013352  0.5013513  0.50135353 0.50138321]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.012233414940885\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000000000001\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.0000000000000187\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000000259512\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000000000018\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000011189876\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.000000000000017\n",
      "output [0.50000001 0.50000001 0.50000001 0.50000001 0.50000001 0.50000001\n",
      " 0.50000001 0.50000001 0.50000001 0.50000001]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000051599731\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.000000000000022\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000000284\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000000000029\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.000000000001698\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000594063\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.50000027 0.50000026 0.50000028 0.50000027 0.50000026 0.50000027\n",
      " 0.50000027 0.50000027 0.50000027 0.50000027]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.00000242162461\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000002896132\n",
      "output [0.50000012 0.50000012 0.50000012 0.50000012 0.50000011 0.50000012\n",
      " 0.50000012 0.50000012 0.50000012 0.50000012]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000010561391477\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.0000000000003797\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000290755655\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000005201364\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.00000000376017\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.50000001 0.50000001 0.50000001 0.50000001 0.50000001 0.50000001\n",
      " 0.50000001 0.50000001 0.50000001 0.50000001]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000059648741\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0000000045797415\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.0000000000004157\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000000000098\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Time Spent: 0.45s\n",
      "\tAccuracy on train set: 0.11.\n",
      "\tAccuracy on test set: 0.02.\n",
      "Iteration 1 of 3.\n",
      "output [0.50000003 0.50000002 0.50000003 0.50000003 0.50000002 0.50000003\n",
      " 0.50000003 0.50000003 0.50000003 0.50000003]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000227846629\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000000000008\n",
      "output [0.50000004 0.50000004 0.50000004 0.50000004 0.50000004 0.50000004\n",
      " 0.50000004 0.50000004 0.50000004 0.50000004]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000003745832204\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000000000005\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000000595\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000000857\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000002116007\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.000000000000001\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.00000000464063\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0000000000000018\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000083116216\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000332704033\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.000000000049164\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000003393\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000049963353\n",
      "output [0.50004449 0.50004383 0.5000449  0.5000442  0.5000436  0.50004399\n",
      " 0.50004395 0.50004418 0.50004424 0.50004459]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000398157913504\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000000082383\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0000000004047944\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.00000000000006\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000001457\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000000140212\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000000000053\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.50019937 0.50019649 0.50020051 0.50019796 0.50019569 0.50019737\n",
      " 0.50019742 0.500198   0.50019807 0.5001997 ]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.001784469325643\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000206173247\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.000000002425732\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.000000000114331\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000006716747\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000199916\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000000018\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5013824  0.50136136 0.50138957 0.50137465 0.50135642 0.50136602\n",
      " 0.50136575 0.50137135 0.50137213 0.50138246]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0123795965483517\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.000000000000001\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000000029763\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000001734364\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.000000000000001\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000011555926\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.000000000000001\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000000018\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000000018\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.000000000000126\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000000006169\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.50000008 0.50000008 0.50000008 0.50000008 0.50000008 0.50000008\n",
      " 0.50000008 0.50000008 0.50000008 0.50000008]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.0000007352003957\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000000336193\n",
      "output [0.50000003 0.50000003 0.50000003 0.50000003 0.50000003 0.50000003\n",
      " 0.50000003 0.50000003 0.50000003 0.50000003]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000282247752\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.000000000000022\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000005162592\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000601763\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000005274163\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000108287086\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.000000000635235\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.000000000000022\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0\n",
      "Epoch: 2, Time Spent: 0.80s\n",
      "\tAccuracy on train set: 0.11.\n",
      "\tAccuracy on test set: 0.01.\n",
      "Iteration 2 of 3.\n",
      "output [0.50000001 0.5        0.50000001 0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5       ]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000447595396\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.50000001 0.50000001 0.50000001 0.50000001 0.50000001 0.50000001\n",
      " 0.50000001 0.50000001 0.50000001 0.50000001]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000753852234\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000000000003\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000000000004\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000002420433\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000005627614\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000010367405\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000047745803\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000000036087\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000000000015\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000000583359\n",
      "output [0.50001638 0.50001625 0.50001647 0.50001632 0.5000162  0.50001628\n",
      " 0.50001627 0.50001632 0.50001633 0.5000164 ]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000146967115013\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000000006805\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0000000000389853\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000000027\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.000000000000006\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000000009495\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000000018\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.50008422 0.50008351 0.50008451 0.50008388 0.50008331 0.50008373\n",
      " 0.50008374 0.50008389 0.5000839  0.50008431]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000755561691718\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000003505\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.0000000003376783\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.000000000012009\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.00000000101284\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000017804\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.50075903 0.50075203 0.50076141 0.50075645 0.50075039 0.50075358\n",
      " 0.50075349 0.50075535 0.50075561 0.50075904]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0068100625383205\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000000006786\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000000490017\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000041319788\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.000000000000023\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000000014015\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.50000004 0.50000004 0.50000004 0.50000004 0.50000004 0.50000004\n",
      " 0.50000004 0.50000004 0.50000004 0.50000004]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.000000326219653\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000000083027\n",
      "output [0.50000001 0.50000001 0.50000001 0.50000001 0.50000001 0.50000001\n",
      " 0.50000001 0.50000001 0.50000001 0.50000001]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000001171500603\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.000000000000004\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0000000016816846\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000000015094\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0000000001495626\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.000000003624258\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "gradie -2.000000000180189\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "gradie -2.0000000000000036\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0\n",
      "output [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "gradie -2.0\n",
      "Epoch: 3, Time Spent: 1.21s\n",
      "\tAccuracy on train set: 0.11.\n",
      "\tAccuracy on test set: 0.01.\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "nn_structure = [784, 350, 10]\n",
    "drnn = DigitRecognitionNN(nn_structure, epochs=3, learninig_rate=0.01)\n",
    "drnn.train(X_train, y_v_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      0\n",
       "1        2      0\n",
       "2        3      2\n",
       "3        4      2\n",
       "4        5      0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = drnn.forward_pass(test.T/255)\n",
    "prediction = np.argmax(output, axis=0)\n",
    "submission = pd.DataFrame({\n",
    "    \"ImageId\": list(range(1, test.shape[0]+1)),\n",
    "    \"Label\": prediction\n",
    "})\n",
    "submission.to_csv(\"../data/digit-recognizer/digit-recognizer-submission.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

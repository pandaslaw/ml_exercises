{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import exp, array, random, dot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import ceil\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image. Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset: (42000, 785)\n",
      "Size of test dataset: (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../data/digit-recognizer/train.csv')\n",
    "test = pd.read_csv('../data/digit-recognizer/test.csv')\n",
    "print(f\"Size of train dataset: {train.shape}\")\n",
    "print(f\"Size of test dataset: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(np.array(train.iloc[0, 1:]).reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.array(train.iloc[1, 1:]).reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "Data preprocessing would include:\n",
    "* Normalize the data (numeric values are rescaled in order to have values between 0 and 1)\n",
    "* Split the dataset on train and validation datasets\n",
    "* Represent target value as zero vector with the length equals to the number of categories and \"1\" value on a position corresponding to a target value, i.e. target value \"4\" will be threated as [0, 0, 0, 0, 1, 0, 0, 0, 0, 0] vector. This is an important step because predicting \"7\" instead of real target value \"8\" is not better than predicting \"0\", both predictions are wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_y(y):\n",
    "    y_vect = np.zeros((len(y), 10))\n",
    "    y_vect[list(range(len(y))), y] = 1\n",
    "    return y_vect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normalized = test.values.astype('float32')\n",
    "test_normalized /= 255\n",
    "\n",
    "X = train.iloc[:, 1:].values.astype('float32')\n",
    "X /= 255\n",
    "y = vectorize_y(train.iloc[:, 0])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=5)\n",
    "\n",
    "X_train, X_test = X_train.T, X_test.T\n",
    "y_train, y_test = y_train.T, y_test.T\n",
    "test_normalized = test_normalized.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE LEARNING ALGORITHM\n",
    "1. Initialize weights and biases randomly\n",
    "2. Iterate over the data<br>\n",
    "    i. Compute the output of neural network using sigmoid function for hidden layers and softmax function for output layer<br>\n",
    "    ii. Compute the loss using the square error loss function<br>\n",
    "    iii. W(new) = W(old) — α ∆W<br>\n",
    "    iv. B(new) = B(old) — α ∆B<br>\n",
    "3. Repeat in order to get minimal error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitRecognitionNN():\n",
    "    def __init__(self, structure, epochs=3, learning_rate=0.01, momentum=0.9, mini_batch_size=16):\n",
    "        self.structure = structure\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        self.cost = []\n",
    "        self.params = self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        params = {}\n",
    "        for i in range(1, len(self.structure)):\n",
    "            params[f'W{i}'] = np.random.randn(self.structure[i], self.structure[i-1]) * np.sqrt(1./self.structure[i-1])\n",
    "            params[f'b{i}'] = np.zeros((self.structure[i], 1))\n",
    "            print(f\"Initialized {i} layer: weights {params[f'W{i}'].shape}, biases {params[f'b{i}'].shape}\")\n",
    "        return params\n",
    "\n",
    "    def sigmoid(self, x, derivative=False):\n",
    "        sigmoid = 1./(1. + np.exp(-x))\n",
    "        if derivative:\n",
    "            return sigmoid * (1 - sigmoid)\n",
    "        return sigmoid\n",
    "\n",
    "    def relu(self, x, derivative=False):\n",
    "        if derivative:\n",
    "            x[x<=0] = 0\n",
    "            x[x>0] = 1\n",
    "        return np.maximum(0,x)\n",
    "\n",
    "    def softmax(self, x, derivative=False):\n",
    "        e = np.exp(x)\n",
    "        softmax = e/np.sum(e, axis=0)\n",
    "        if derivative:\n",
    "            softmax = softmax.reshape(-1,1)\n",
    "            return np.diagflat(softmax) - np.dot(softmax, softmax.T)\n",
    "        return softmax\n",
    "\n",
    "    def forward_pass(self, x_train):\n",
    "        self.params['A0'] = x_train\n",
    "        for i in range(1, len(self.structure)):\n",
    "            self.params[f'Z{i}'] = np.dot(self.params[f'W{i}'], self.params[f'A{i-1}'])\n",
    "            self.params[f'Z{i}'] += self.params[f'b{i}']\n",
    "            self.params[f'A{i}'] = self.sigmoid(self.params[f'Z{i}'])\n",
    "        last_layer = len(self.structure)-1\n",
    "        self.params[f'A{last_layer}'] = self.softmax(self.params[f'Z{last_layer}'])\n",
    "        return self.params[f'A{last_layer}']\n",
    "        \n",
    "    def backward_pass(self, x_train, y_train):\n",
    "        gradients = {}\n",
    "        last_gradient_index = len(self.structure)-1\n",
    "        delta =  self.params[f'A{last_gradient_index}'] - y_train\n",
    "        gradients[f'W{last_gradient_index}'] = np.dot(delta, self.params[f'A{last_gradient_index-1}'].T)\n",
    "        gradients[f'b{last_gradient_index}'] = np.sum(delta, axis=1, keepdims=True)\n",
    "        for i in range(len(self.structure)-2, 0, -1):\n",
    "            delta = np.dot(self.params[f'W{i+1}'].T, delta) * self.sigmoid(self.params[f'Z{i}'], derivative=True)\n",
    "            gradients[f'W{i}'] = (1. / self.mini_batch_size) * np.dot(delta, self.params[f'A{i-1}'].T)\n",
    "            gradients[f'b{i}'] = (1. / self.mini_batch_size) * np.sum(delta, axis=1, keepdims=True)\n",
    "        return gradients\n",
    "\n",
    "    def compute_accuracy(self, X, Y):\n",
    "        predictions = []\n",
    "        output = self.forward_pass(X)\n",
    "        pred = np.argmax(output, axis=0)\n",
    "        total = sum(pred == np.argmax(Y, axis=0))\n",
    "        return total/len(pred)\n",
    "\n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        \"\"\"Train the neural network using mini-batch stochastic gradient descent\"\"\"\n",
    "        n = X_train.shape[1]\n",
    "        start_time = time.time()\n",
    "        delta = {}\n",
    "        for i in range(1, len(self.structure)):\n",
    "            delta[f'W{i}'] = np.zeros((self.structure[i], self.structure[i-1]))\n",
    "            delta[f'b{i}'] = np.zeros((self.structure[i], 1))\n",
    "        for epoch in range(self.epochs):\n",
    "            shuffle_index = np.random.permutation(n)\n",
    "            training_data_x = x_train[:, shuffle_index]\n",
    "            training_data_y = y_train[:, shuffle_index]\n",
    "            for i in range(ceil(self.structure[0]/self.mini_batch_size)):\n",
    "                begin = epoch * self.mini_batch_size\n",
    "                end = min(begin + self.mini_batch_size, x_train.shape[1] - 1)\n",
    "                X = training_data_x[:, begin:end]\n",
    "                Y = training_data_y[:, begin:end]\n",
    "                self.forward_pass(X)\n",
    "                gradients = self.backward_pass(X, Y)\n",
    "                for k in range(1, len(self.structure)):\n",
    "                    delta_W = -self.learning_rate * gradients[f'W{k}'] #+ self.momentum * delta[f'W{k}']\n",
    "                    delta_b = -self.learning_rate * gradients[f'b{k}'] #+ self.momentum * delta[f'b{k}']\n",
    "#                     delta[f'W{k}'] = delta_W\n",
    "#                     delta[f'b{k}'] = delta_b\n",
    "                    self.params[f'W{k}'] += delta_W\n",
    "                    self.params[f'b{k}'] += delta_b\n",
    "            train_accuracy = self.compute_accuracy(x_train, y_train)\n",
    "            test_accuracy = self.compute_accuracy(x_val, y_val)\n",
    "            print(\"Epoch {}. Time spent: {:.2f}. Accuracy on train set: {:.2f}%. Accuracy on test set: {:.2f}%.\".format(\n",
    "                epoch+1, time.time() - start_time, train_accuracy*100, test_accuracy*100))\n",
    "        print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting epochs to 50\n",
      "Setting learn rate to 0.4\n",
      "Setting momentum to 0.9\n",
      "Setting batch size to 64\n",
      "Initialized 1 layer: weights (64, 784), biases (64, 1)\n",
      "Initialized 2 layer: weights (10, 64), biases (10, 1)\n",
      "Epoch 1. Time spent: 2.02. Accuracy on train set: 10.02%. Accuracy on test set: 10.98%.\n",
      "Epoch 2. Time spent: 3.58. Accuracy on train set: 10.17%. Accuracy on test set: 9.36%.\n",
      "Epoch 3. Time spent: 4.78. Accuracy on train set: 24.33%. Accuracy on test set: 24.43%.\n",
      "Epoch 4. Time spent: 6.06. Accuracy on train set: 24.78%. Accuracy on test set: 25.40%.\n",
      "Epoch 5. Time spent: 7.20. Accuracy on train set: 19.83%. Accuracy on test set: 20.21%.\n",
      "Epoch 6. Time spent: 8.31. Accuracy on train set: 39.38%. Accuracy on test set: 39.71%.\n",
      "Epoch 7. Time spent: 9.42. Accuracy on train set: 49.18%. Accuracy on test set: 49.79%.\n",
      "Epoch 8. Time spent: 10.51. Accuracy on train set: 57.89%. Accuracy on test set: 58.19%.\n",
      "Epoch 9. Time spent: 11.58. Accuracy on train set: 58.75%. Accuracy on test set: 59.74%.\n",
      "Epoch 10. Time spent: 12.82. Accuracy on train set: 67.48%. Accuracy on test set: 68.07%.\n",
      "Epoch 11. Time spent: 14.30. Accuracy on train set: 56.47%. Accuracy on test set: 57.48%.\n",
      "Epoch 12. Time spent: 15.40. Accuracy on train set: 69.44%. Accuracy on test set: 69.79%.\n",
      "Epoch 13. Time spent: 16.73. Accuracy on train set: 59.95%. Accuracy on test set: 60.71%.\n",
      "Epoch 14. Time spent: 18.05. Accuracy on train set: 60.11%. Accuracy on test set: 59.17%.\n",
      "Epoch 15. Time spent: 19.30. Accuracy on train set: 72.61%. Accuracy on test set: 72.83%.\n",
      "Epoch 16. Time spent: 20.58. Accuracy on train set: 75.42%. Accuracy on test set: 75.36%.\n",
      "Epoch 17. Time spent: 21.85. Accuracy on train set: 74.58%. Accuracy on test set: 73.90%.\n",
      "Epoch 18. Time spent: 23.12. Accuracy on train set: 77.85%. Accuracy on test set: 77.79%.\n",
      "Epoch 19. Time spent: 24.51. Accuracy on train set: 75.36%. Accuracy on test set: 75.17%.\n",
      "Epoch 20. Time spent: 25.83. Accuracy on train set: 76.46%. Accuracy on test set: 76.90%.\n",
      "Epoch 21. Time spent: 27.03. Accuracy on train set: 78.59%. Accuracy on test set: 78.67%.\n",
      "Epoch 22. Time spent: 28.17. Accuracy on train set: 79.00%. Accuracy on test set: 79.07%.\n",
      "Epoch 23. Time spent: 29.32. Accuracy on train set: 78.33%. Accuracy on test set: 79.05%.\n",
      "Epoch 24. Time spent: 30.49. Accuracy on train set: 80.62%. Accuracy on test set: 80.38%.\n",
      "Epoch 25. Time spent: 31.63. Accuracy on train set: 81.46%. Accuracy on test set: 81.81%.\n",
      "Epoch 26. Time spent: 32.77. Accuracy on train set: 80.35%. Accuracy on test set: 80.40%.\n",
      "Epoch 27. Time spent: 33.91. Accuracy on train set: 81.19%. Accuracy on test set: 81.67%.\n",
      "Epoch 28. Time spent: 35.10. Accuracy on train set: 78.78%. Accuracy on test set: 78.19%.\n",
      "Epoch 29. Time spent: 36.49. Accuracy on train set: 81.66%. Accuracy on test set: 81.48%.\n",
      "Epoch 30. Time spent: 37.72. Accuracy on train set: 82.17%. Accuracy on test set: 81.69%.\n",
      "Epoch 31. Time spent: 38.86. Accuracy on train set: 80.96%. Accuracy on test set: 80.64%.\n",
      "Epoch 32. Time spent: 40.04. Accuracy on train set: 81.80%. Accuracy on test set: 81.52%.\n",
      "Epoch 33. Time spent: 41.21. Accuracy on train set: 77.88%. Accuracy on test set: 77.36%.\n",
      "Epoch 34. Time spent: 42.43. Accuracy on train set: 82.53%. Accuracy on test set: 82.83%.\n",
      "Epoch 35. Time spent: 43.58. Accuracy on train set: 82.79%. Accuracy on test set: 82.67%.\n",
      "Epoch 36. Time spent: 44.73. Accuracy on train set: 81.84%. Accuracy on test set: 82.07%.\n",
      "Epoch 37. Time spent: 46.02. Accuracy on train set: 83.88%. Accuracy on test set: 83.69%.\n",
      "Epoch 38. Time spent: 47.26. Accuracy on train set: 80.89%. Accuracy on test set: 81.00%.\n",
      "Epoch 39. Time spent: 48.56. Accuracy on train set: 83.80%. Accuracy on test set: 84.19%.\n",
      "Epoch 40. Time spent: 49.85. Accuracy on train set: 85.09%. Accuracy on test set: 85.38%.\n",
      "Epoch 41. Time spent: 51.17. Accuracy on train set: 82.49%. Accuracy on test set: 82.81%.\n",
      "Epoch 42. Time spent: 52.50. Accuracy on train set: 84.11%. Accuracy on test set: 83.50%.\n",
      "Epoch 43. Time spent: 53.78. Accuracy on train set: 84.15%. Accuracy on test set: 83.90%.\n",
      "Epoch 44. Time spent: 55.06. Accuracy on train set: 83.32%. Accuracy on test set: 83.38%.\n",
      "Epoch 45. Time spent: 56.32. Accuracy on train set: 82.66%. Accuracy on test set: 83.00%.\n",
      "Epoch 46. Time spent: 57.61. Accuracy on train set: 82.43%. Accuracy on test set: 82.10%.\n",
      "Epoch 47. Time spent: 58.86. Accuracy on train set: 80.71%. Accuracy on test set: 80.50%.\n",
      "Epoch 48. Time spent: 60.10. Accuracy on train set: 83.57%. Accuracy on test set: 83.36%.\n",
      "Epoch 49. Time spent: 61.34. Accuracy on train set: 81.61%. Accuracy on test set: 81.24%.\n",
      "Epoch 50. Time spent: 62.60. Accuracy on train set: 85.50%. Accuracy on test set: 85.36%.\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "# nn_structure = [784, 128, 64, 10]\n",
    "# nn_structure = [784, 350, 10]\n",
    "# nn_structure = [784, 512, 512, 10]\n",
    "nn_structure = [784, 64, 10]\n",
    "epochs = 50\n",
    "learning_rate = 0.4\n",
    "momentum = 0.9\n",
    "mini_batch_size = 64\n",
    "print(f\"Setting epochs to {epochs}\")\n",
    "print(f\"Setting learn rate to {learning_rate}\")\n",
    "print(f\"Setting momentum to {momentum}\")\n",
    "print(f\"Setting batch size to {mini_batch_size}\")\n",
    "# key tips:\n",
    "# 1) activation function, which one works better\n",
    "# 2) run with small and big learning rates\n",
    "# 3) number of layers, number of neurons, batch size\n",
    "# 4) try to wait for more epochs\n",
    "drnn = DigitRecognitionNN(nn_structure, epochs=epochs, learning_rate=learning_rate, \n",
    "                          momentum=momentum, mini_batch_size=mini_batch_size)\n",
    "drnn.train(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      9\n",
       "4        5      2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = []\n",
    "output = drnn.forward_pass(test_normalized)\n",
    "prediction = np.argmax(output, axis=0)\n",
    "submission = pd.DataFrame({\n",
    "    \"ImageId\": list(range(1, test.shape[0]+1)),\n",
    "    \"Label\": prediction\n",
    "})\n",
    "submission.to_csv(\"../data/digit-recognizer/digit-recognizer-submission.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

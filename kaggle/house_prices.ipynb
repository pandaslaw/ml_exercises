{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling # https://github.com/pandas-profiling/pandas-profiling\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import qgrid\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, norm\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "\n",
    "np.random.seed(12345)\n",
    "sns.set_style(\"dark\")\n",
    "# plt.rcParams['figure.figsize'] = 12, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1da78fca450f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/house-prices/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/house-prices/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# qgrid_widget = qgrid.show_grid(train, show_toolbar=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train = load_dataset('../data/house-prices/train.csv')\n",
    "test = load_dataset('../data/house-prices/test.csv')\n",
    "y_train = train['SalePrice']\n",
    "test_ids = test['Id']\n",
    "# qgrid_widget = qgrid.show_grid(train, show_toolbar=True)\n",
    "# qgrid_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data and get insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get statistics by every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = pandas_profiling.ProfileReport(train, title='Pandas Profiling Report')\n",
    "# profile.to_file(output_file=\"../data/house-prices/train_profiling_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target value distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_train, fit=norm)\n",
    "# QQ plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(y_train, plot=plt)\n",
    "plt.show()\n",
    "print(f\"skewness: {y_train.skew()}\")\n",
    "print(f\"kurtosis: {y_train.kurt()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the target\n",
    "salePrice = np.log1p(y_train)\n",
    "sns.distplot(salePrice, fit=norm)\n",
    "# QQ plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(salePrice, plot=plt)\n",
    "plt.show()\n",
    "print(f\"skewness: {salePrice.skew()}\")\n",
    "print(f\"kurtosis: {salePrice.kurt()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Select impactful predictors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_matrix = train.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corr_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_columns = corr_matrix.nlargest(10, 'SalePrice')['SalePrice'].index\n",
    "corr_coefficients = np.corrcoef(train[corr_columns].values.T)\n",
    "hm = sns.heatmap(corr_coefficients, annot=True, annot_kws={'size': 10}, xticklabels=corr_columns.values, \n",
    "                 yticklabels=corr_columns.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr_columns = [x for x in corr_columns if x != 'SalePrice']\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "for i, column in enumerate(corr_columns):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "    plt.scatter(train[corr_columns[i]], train['SalePrice'])\n",
    "    plt.xlabel(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess datasets\n",
    "\n",
    "Numeric features that are highly correlated with the SalePrice:\n",
    "\n",
    "- OverallQual: Rates the overall material and finish of the house\n",
    "- GrLivArea: Above grade (ground) living area square feet\n",
    "- GarageCars: Size of garage in car capacity\n",
    "- GarageArea: Size of garage in square feet\n",
    "- TotalBsmtSF: Total square feet of basement area\n",
    "- 1stFlrSF: First Floor square feet\n",
    "- FullBath: Full bathrooms above grade       \t\n",
    "- TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
    "- YearBuilt: Original construction date\n",
    "\n",
    "Data preprocessing would include:\n",
    "* Merge train and test datasets\n",
    "* Fill missing values\n",
    "* Encode categorical data\n",
    "* Standardization (numeric values are rescaled in order to have mean=0 and standard deviation=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete outliers\n",
    "# train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)\n",
    "\n",
    "# merge train and test datasets\n",
    "train.drop(['Id', 'SalePrice'], axis=1, inplace=True)\n",
    "test.drop(['Id'], axis=1, inplace=True)\n",
    "all_data = pd.concat((train, test), axis=0)\n",
    "print(\"all_data size: {} \".format(all_data.shape))\n",
    "column_names = list(all_data.columns)\n",
    "# find columns with N/A\n",
    "columns_with_na = []\n",
    "for column in all_data:\n",
    "    if sum(all_data[column].isnull()) > 0:\n",
    "        columns_with_na.append(column)\n",
    "print(f\"Columns with N/A values ({len(columns_with_na)} of {all_data.shape[1]})\")\n",
    "# fill N/A with a dict where a column mapped to a most common value\n",
    "fillna_dict = dict((col, all_data[col].value_counts().idxmax()) for col in columns_with_na)\n",
    "all_data.fillna(value=fillna_dict, inplace=True)\n",
    "# encode all categorical features\n",
    "all_data = all_data.astype(str)\n",
    "oe = OrdinalEncoder()\n",
    "oe.fit(all_data)\n",
    "all_data = oe.transform(all_data)\n",
    "# scale all_data\n",
    "scaler = StandardScaler()\n",
    "all_data = scaler.fit_transform(all_data)\n",
    "# scale y_train\n",
    "y_scaler = StandardScaler()\n",
    "y_train = y_scaler.fit_transform(pd.DataFrame(y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = train.shape[0]\n",
    "X_train = pd.DataFrame(all_data[:n_train])\n",
    "X_test = pd.DataFrame(all_data[n_train:])\n",
    "# select features\n",
    "amount = 10\n",
    "fs = SelectKBest(score_func=f_regression, k=amount)\n",
    "fs.fit(X_train, y_train.ravel())\n",
    "X_train_fs = fs.transform(X_train)\n",
    "X_test_fs = fs.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the importance of features\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "plt.bar(column_names, fs.scores_)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "# for i in range(len(fs.scores_)):\n",
    "# print(f'Feature {i}: {fs.scores_[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
    "crossval_results = cross_val_score(model, X_train_fs, y_train, cv=kfold, scoring=scoring)\n",
    "print(f\"LinearRegression: mean={crossval_results.mean()}, std={crossval_results.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 100\n",
    "# TODO: get more info about indexing in pandas/numpy\n",
    "my_X_train = X_train_fs[:X_train_fs.shape[0]-test_size, :]\n",
    "my_X_test = X_train_fs[X_train_fs.shape[0]-test_size:, :]\n",
    "my_y_train = y_train[:y_train.shape[0]-test_size]\n",
    "my_y_test = y_train[y_train.shape[0]-test_size:]\n",
    "\n",
    "my_model = LinearRegression()\n",
    "my_scoring = 'neg_mean_squared_error'\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
    "my_crossval_results = cross_val_score(\n",
    "    my_model, my_X_train, my_y_train, cv=kfold, scoring=my_scoring)\n",
    "print(f\"({name}: mean={my_crossval_results.mean()}, std={my_crossval_results.std()})\")\n",
    "\n",
    "my_model.fit(my_X_train, my_y_train)\n",
    "print(f'Accuracy (R^2) of LinReg model on training set: {my_model.score(my_X_train, my_y_train)}')\n",
    "print(f'Accuracy (R^2) of LinReg model on test set: {my_model.score(my_X_test, my_y_test)}')\n",
    "\n",
    "my_y_train_pred = my_model.predict(my_X_train)\n",
    "my_X_test_pred = my_model.predict(my_X_test)\n",
    "# print(\"mean_squared_log_error on training set:\", mean_squared_log_error(my_y_train, my_y_train_pred))\n",
    "# print(\"mean_squared_log_error on test set:\", mean_squared_log_error(my_y_test, my_X_test_pred))\n",
    "print(f\"mean_squared_error on training set:\", mean_squared_error(my_y_train, my_y_train_pred))\n",
    "print(f\"mean_squared_error on test set:\", mean_squared_error(my_y_test, my_X_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_fs, y_train)\n",
    "print(\"Accuracy (R^2) of LinReg model on training set:\", model.score(X_train_fs, y_train))\n",
    "prediction = model.predict(X_test_fs)\n",
    "prediction = prediction.ravel()\n",
    "prediction = y_scaler.inverse_transform(prediction)\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": test_ids,\n",
    "    \"SalePrice\": prediction\n",
    "})\n",
    "submission.to_csv(\"../data/house-prices/house-prices-submission.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

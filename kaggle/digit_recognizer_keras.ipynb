{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version of solving digit recognition problem using MNIST dataset is implemented using keras: simple neural network and colvolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.datasets import mnist\n",
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras import utils\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image. Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/digit-recognizer/train.csv')\n",
    "test = pd.read_csv('../data/digit-recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Data preprocessing would include:\n",
    "* Normalize the data (numeric values are rescaled in order to have values between 0 and 1)\n",
    "* Split the dataset on train and validation datasets\n",
    "* Represent target value as zero vector with the length equals to the number of categories and \"1\" value on a position corresponding to a target value, i.e. target value \"4\" will be threated as [0, 0, 0, 0, 1, 0, 0, 0, 0, 0] vector. This is an important step because predicting \"7\" instead of real target value \"8\" is not better than predicting \"0\", both predictions are wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normalized = test.values.astype('float32')\n",
    "test_normalized /= 255\n",
    "\n",
    "X = train.iloc[:, 1:].values.astype('float32')\n",
    "X /= 255\n",
    "y = utils.to_categorical(train.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple multi-layer neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/20\n",
      " - 3s - loss: 6.8504 - acc: 0.4727 - val_loss: 4.1784 - val_acc: 0.6407\n",
      "Epoch 2/20\n",
      " - 3s - loss: 2.9171 - acc: 0.7099 - val_loss: 1.9541 - val_acc: 0.7576\n",
      "Epoch 3/20\n",
      " - 3s - loss: 1.5870 - acc: 0.7919 - val_loss: 1.3228 - val_acc: 0.8014\n",
      "Epoch 4/20\n",
      " - 3s - loss: 1.1496 - acc: 0.8197 - val_loss: 1.0287 - val_acc: 0.8226\n",
      "Epoch 5/20\n",
      " - 3s - loss: 0.8940 - acc: 0.8356 - val_loss: 0.8420 - val_acc: 0.8357\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.7314 - acc: 0.8503 - val_loss: 0.7180 - val_acc: 0.8467\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.6224 - acc: 0.8631 - val_loss: 0.6306 - val_acc: 0.8605\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.5423 - acc: 0.8754 - val_loss: 0.5588 - val_acc: 0.8693\n",
      "Epoch 9/20\n",
      " - 3s - loss: 0.4783 - acc: 0.8843 - val_loss: 0.5098 - val_acc: 0.8800\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.4291 - acc: 0.8935 - val_loss: 0.4629 - val_acc: 0.8881\n",
      "Epoch 11/20\n",
      " - 3s - loss: 0.3867 - acc: 0.9016 - val_loss: 0.4295 - val_acc: 0.8960\n",
      "Epoch 12/20\n",
      " - 3s - loss: 0.3506 - acc: 0.9091 - val_loss: 0.4012 - val_acc: 0.9010\n",
      "Epoch 13/20\n",
      " - 3s - loss: 0.3201 - acc: 0.9145 - val_loss: 0.3839 - val_acc: 0.9026\n",
      "Epoch 14/20\n",
      " - 3s - loss: 0.2946 - acc: 0.9202 - val_loss: 0.3616 - val_acc: 0.9074\n",
      "Epoch 15/20\n",
      " - 3s - loss: 0.2717 - acc: 0.9253 - val_loss: 0.3471 - val_acc: 0.9114\n",
      "Epoch 16/20\n",
      " - 3s - loss: 0.2533 - acc: 0.9297 - val_loss: 0.3269 - val_acc: 0.9164\n",
      "Epoch 17/20\n",
      " - 3s - loss: 0.2360 - acc: 0.9347 - val_loss: 0.3146 - val_acc: 0.9200\n",
      "Epoch 18/20\n",
      " - 3s - loss: 0.2212 - acc: 0.9384 - val_loss: 0.3070 - val_acc: 0.9229\n",
      "Epoch 19/20\n",
      " - 3s - loss: 0.2075 - acc: 0.9414 - val_loss: 0.2966 - val_acc: 0.9221\n",
      "Epoch 20/20\n",
      " - 3s - loss: 0.1969 - acc: 0.9443 - val_loss: 0.2892 - val_acc: 0.9274\n",
      "Simple NN prediction error: 7.26%\n"
     ]
    }
   ],
   "source": [
    "num_pixels = 784\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "hidden_layer_size = 32\n",
    "num_classes = 10\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=5)\n",
    "\n",
    "def create_simple_nn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer_size, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_simple_nn_model()\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Simple NN prediction error: {100-scores[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple convolutional neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=5)\n",
    "# reshape in order to have [samples][width][height][channels] shape\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================]37800/37800 [==============================] - 48s 1ms/step - loss: 0.2962 - acc: 0.9165 - val_loss: 0.1001 - val_acc: 0.9688\n",
      "\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================]37800/37800 [==============================] - 45s 1ms/step - loss: 0.0865 - acc: 0.9744 - val_loss: 0.0703 - val_acc: 0.9800\n",
      "\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================]37800/37800 [==============================] - 45s 1ms/step - loss: 0.0595 - acc: 0.9817 - val_loss: 0.0619 - val_acc: 0.9807\n",
      "\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================]37800/37800 [==============================] - 45s 1ms/step - loss: 0.0461 - acc: 0.9858 - val_loss: 0.0607 - val_acc: 0.9788\n",
      "\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================]37800/37800 [==============================] - 46s 1ms/step - loss: 0.0382 - acc: 0.9882 - val_loss: 0.0496 - val_acc: 0.9843\n",
      "\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================]37800/37800 [==============================] - 50s 1ms/step - loss: 0.0307 - acc: 0.9904 - val_loss: 0.0517 - val_acc: 0.9852\n",
      "\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================]37800/37800 [==============================] - 47s 1ms/step - loss: 0.0271 - acc: 0.9909 - val_loss: 0.0544 - val_acc: 0.9838\n",
      "\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================]37800/37800 [==============================] - 49s 1ms/step - loss: 0.0237 - acc: 0.9928 - val_loss: 0.0483 - val_acc: 0.9848\n",
      "\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================]37800/37800 [==============================] - 51s 1ms/step - loss: 0.0194 - acc: 0.9941 - val_loss: 0.0475 - val_acc: 0.9876\n",
      "\n",
      "Epoch 10/10\n",
      "37800/37800 [==============================]37800/37800 [==============================] - 50s 1ms/step - loss: 0.0154 - acc: 0.9953 - val_loss: 0.0485 - val_acc: 0.9860\n",
      "\n",
      "Convolutional NN prediction error: 1.40%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "epochs = 10\n",
    "\n",
    "def create_conv_nn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "cnn_model = create_conv_nn_model()\n",
    "cnn_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size)\n",
    "scores = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Convolutional NN prediction error: {100-scores[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      4\n",
       "4        5      3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = []\n",
    "output = model.predict(test_normalized)\n",
    "prediction = np.argmax(output, axis=1)\n",
    "submission = pd.DataFrame({\n",
    "    \"ImageId\": list(range(1, test.shape[0]+1)),\n",
    "    \"Label\": prediction\n",
    "})\n",
    "submission.to_csv(\"../data/digit-recognizer/digit-recognizer-submission.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
